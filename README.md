# Kaggle-Titanic-Machine-Learning-from-Disaster

![](https://media.nationalgeographic.org/assets/photos/000/273/27302.jpg)


Directory structure
------------
     
    ├── input
    │   └─── datasets      <- Datasets used in model
    │
    ├── notebook + model   <- Jupyter notebooks and model used in this competition. 
    │   └─── exploring-machine-learning-algorithms.ipynb     
    │
    ├── LICENSE
    └── README.md   
--------


## About:
A machine learning model that predicts which passengers survived the Titanic shipwreck. This is a knowledge(type) competition on [Kaggle](https://www.kaggle.com/c/titanic).


## Motivation/Idea:
This is the first ML model which I created for any problem. I heard a lot  about this competition. This competition is also known as the `Hello World` of Data Science/Machine Learning.

## Approach:

Before solving this problem I tried to get the insights about the dataset(Which is a tradional way to solve any machine learning problem). After that I implemented some machine learning algorithms which is listed below(imported from `scikit-learn` library):
- Random Forest
- Decision Tree
- KNN
- Logistic Regression
- Linear SVC
- Perceptron
- Support Vector Machine
- Stochastic Gradient Decent
- Naive Bayes

## Result/Outcome:

Accuracy of the algorithms is listed below:

- `Random Forest ──  86.76`
- `Decision Tree ──  86.76`
- `KNN ──  84.74`
- `Logistic Regression ──  80.36`
- `Linear SVC ──  79.12`
- `Perceptron ──  78.34`
- `Support Vector Machines ──  78.23`
- `Stochastic Gradient Decent ──  74.07`
- `Naive Bayes ──  72.28`


